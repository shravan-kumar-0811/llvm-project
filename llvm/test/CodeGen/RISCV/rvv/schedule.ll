; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=riscv64 -mcpu=sifive-x280 -verify-machineinstrs < %s \
; RUN:   | FileCheck %s --check-prefix=DEFAULT
; RUN: llc -mtriple=riscv64 -mcpu=sifive-x280 -misched-bottomup=true -misched-topdown=false \
; RUN:   -riscv-enable-schedule-same-vtype -verify-machineinstrs < %s \
; RUN:   | FileCheck %s --check-prefix=SAME-VTYPE-FIRST-BOTTOMUP
; RUN: llc -mtriple=riscv64 -mcpu=sifive-x280 -misched-bottomup=false -misched-topdown=true \
; RUN:   -riscv-enable-schedule-same-vtype -verify-machineinstrs < %s \
; RUN:   | FileCheck %s --check-prefix=SAME-VTYPE-FIRST-TOPDOWN
; RUN: llc -mtriple=riscv64 -mcpu=sifive-x280 -misched-bottomup=false -misched-topdown=false \
; RUN:   -riscv-enable-schedule-same-vtype -verify-machineinstrs < %s \
; RUN:   | FileCheck %s --check-prefix=SAME-VTYPE-FIRST-BIDIRECTIONAL

declare void @consume(i64 %scalar, <vscale x 1 x i64> %vector)

define void @test(i64 %a, i64 %b, <vscale x 1 x i64> %v64_0, <vscale x 1 x i64> %v64_1, <vscale x 1 x i32> %v32_0, <vscale x 1 x i32> %v32_1) {
; DEFAULT-LABEL: test:
; DEFAULT:       # %bb.0: # %entry
; DEFAULT-NEXT:    addi sp, sp, -16
; DEFAULT-NEXT:    .cfi_def_cfa_offset 16
; DEFAULT-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; DEFAULT-NEXT:    .cfi_offset ra, -8
; DEFAULT-NEXT:    vsetvli a2, zero, e64, m1, ta, ma
; DEFAULT-NEXT:    vdiv.vv v12, v8, v9
; DEFAULT-NEXT:    vsetvli zero, zero, e32, mf2, ta, ma
; DEFAULT-NEXT:    div a2, a0, a1
; DEFAULT-NEXT:    add a3, a0, a1
; DEFAULT-NEXT:    mul a0, a0, a1
; DEFAULT-NEXT:    add a0, a0, a3
; DEFAULT-NEXT:    add a0, a0, a2
; DEFAULT-NEXT:    vdiv.vv v13, v10, v11
; DEFAULT-NEXT:    vsetvli zero, zero, e64, m1, ta, ma
; DEFAULT-NEXT:    vadd.vv v8, v8, v9
; DEFAULT-NEXT:    vsetvli zero, zero, e32, mf2, ta, ma
; DEFAULT-NEXT:    vadd.vv v9, v10, v11
; DEFAULT-NEXT:    vsetvli zero, zero, e64, m1, ta, ma
; DEFAULT-NEXT:    vadd.vv v8, v8, v12
; DEFAULT-NEXT:    vsetvli zero, zero, e32, mf2, ta, ma
; DEFAULT-NEXT:    vadd.vv v9, v9, v13
; DEFAULT-NEXT:    vwadd.wv v8, v8, v9
; DEFAULT-NEXT:    call consume
; DEFAULT-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; DEFAULT-NEXT:    addi sp, sp, 16
; DEFAULT-NEXT:    ret
;
; SAME-VTYPE-FIRST-BOTTOMUP-LABEL: test:
; SAME-VTYPE-FIRST-BOTTOMUP:       # %bb.0: # %entry
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    addi sp, sp, -16
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    .cfi_def_cfa_offset 16
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    .cfi_offset ra, -8
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vsetvli a2, zero, e64, m1, ta, ma
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vadd.vv v12, v8, v9
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    div a2, a0, a1
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    add a3, a0, a1
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vdiv.vv v8, v8, v9
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    mul a0, a0, a1
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    add a0, a0, a3
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    add a0, a0, a2
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vadd.vv v8, v12, v8
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vsetvli zero, zero, e32, mf2, ta, ma
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vadd.vv v9, v10, v11
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vdiv.vv v10, v10, v11
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vadd.vv v9, v9, v10
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    vwadd.wv v8, v8, v9
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    call consume
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    addi sp, sp, 16
; SAME-VTYPE-FIRST-BOTTOMUP-NEXT:    ret
;
; SAME-VTYPE-FIRST-TOPDOWN-LABEL: test:
; SAME-VTYPE-FIRST-TOPDOWN:       # %bb.0: # %entry
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    addi sp, sp, -16
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    .cfi_def_cfa_offset 16
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    .cfi_offset ra, -8
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vsetvli a3, zero, e32, mf2, ta, ma
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vadd.vv v12, v10, v11
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vdiv.vv v10, v10, v11
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    add a2, a0, a1
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    mul a3, a0, a1
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    div a0, a0, a1
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    add a2, a2, a3
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vadd.vv v10, v12, v10
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vsetvli zero, zero, e64, m1, ta, ma
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vadd.vv v11, v8, v9
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vdiv.vv v8, v8, v9
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    add a0, a0, a2
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vadd.vv v8, v11, v8
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vsetvli zero, zero, e32, mf2, ta, ma
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    vwadd.wv v8, v8, v10
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    call consume
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    addi sp, sp, 16
; SAME-VTYPE-FIRST-TOPDOWN-NEXT:    ret
;
; SAME-VTYPE-FIRST-BIDIRECTIONAL-LABEL: test:
; SAME-VTYPE-FIRST-BIDIRECTIONAL:       # %bb.0: # %entry
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    addi sp, sp, -16
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    .cfi_def_cfa_offset 16
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    .cfi_offset ra, -8
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vsetvli a2, zero, e32, mf2, ta, ma
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vadd.vv v12, v10, v11
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vdiv.vv v10, v10, v11
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vsetvli zero, zero, e64, m1, ta, ma
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    div a2, a0, a1
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    add a3, a0, a1
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    mul a0, a0, a1
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    add a0, a0, a3
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vadd.vv v11, v8, v9
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vdiv.vv v8, v8, v9
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    add a0, a0, a2
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vadd.vv v8, v11, v8
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vsetvli zero, zero, e32, mf2, ta, ma
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vadd.vv v9, v12, v10
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    vwadd.wv v8, v8, v9
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    call consume
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    addi sp, sp, 16
; SAME-VTYPE-FIRST-BIDIRECTIONAL-NEXT:    ret
entry:
  %0 = add <vscale x 1 x i64> %v64_0, %v64_1
  %scalar0 = add i64 %a, %b
  %1 = add <vscale x 1 x i32> %v32_0, %v32_1
  %2 = sdiv <vscale x 1 x i64> %v64_0, %v64_1
  %scalar1 = mul i64 %a, %b
  %3 = sdiv <vscale x 1 x i32> %v32_0, %v32_1
  %4 = add <vscale x 1 x i64> %0, %2
  %scalar2 = sdiv i64 %a, %b
  %5 = add <vscale x 1 x i32> %1, %3

  %6 = sext <vscale x 1 x i32> %5 to <vscale x 1 x i64>
  %scalar3 = add i64 %scalar0, %scalar1
  %7 = add <vscale x 1 x i64> %4, %6
  %scalar4 = add i64 %scalar2, %scalar3
  call void @consume(i64 %scalar4, <vscale x 1 x i64> %7)
  ret void
}

