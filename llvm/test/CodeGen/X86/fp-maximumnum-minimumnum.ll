; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc --mtriple=x86_64 < %s | FileCheck %s --check-prefix=X86-64

declare float @llvm.maximumnum.f32(float, float)
declare double @llvm.maximumnum.f64(double, double)
declare float @llvm.minimumnum.f32(float, float)
declare double @llvm.minimumnum.f64(double, double)

define float @maximumnum_float(float %x, float %y) {
;
; X86-64-LABEL: maximumnum_float:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movaps %xmm0, %xmm2
; X86-64-NEXT:    cmpunordss %xmm0, %xmm2
; X86-64-NEXT:    movaps %xmm2, %xmm3
; X86-64-NEXT:    andps %xmm1, %xmm3
; X86-64-NEXT:    andnps %xmm0, %xmm2
; X86-64-NEXT:    orps %xmm3, %xmm2
; X86-64-NEXT:    movaps %xmm1, %xmm3
; X86-64-NEXT:    cmpunordss %xmm1, %xmm3
; X86-64-NEXT:    movaps %xmm3, %xmm0
; X86-64-NEXT:    andps %xmm2, %xmm0
; X86-64-NEXT:    andnps %xmm1, %xmm3
; X86-64-NEXT:    orps %xmm0, %xmm3
; X86-64-NEXT:    movaps %xmm3, %xmm0
; X86-64-NEXT:    cmpltss %xmm2, %xmm0
; X86-64-NEXT:    movaps %xmm0, %xmm1
; X86-64-NEXT:    andps %xmm2, %xmm1
; X86-64-NEXT:    andnps %xmm3, %xmm0
; X86-64-NEXT:    orps %xmm1, %xmm0
; X86-64-NEXT:    movaps %xmm0, %xmm1
; X86-64-NEXT:    addss %xmm0, %xmm1
; X86-64-NEXT:    movaps %xmm0, %xmm4
; X86-64-NEXT:    cmpunordss %xmm0, %xmm4
; X86-64-NEXT:    andps %xmm4, %xmm1
; X86-64-NEXT:    andnps %xmm0, %xmm4
; X86-64-NEXT:    orps %xmm1, %xmm4
; X86-64-NEXT:    xorps %xmm1, %xmm1
; X86-64-NEXT:    cmpeqss %xmm4, %xmm1
; X86-64-NEXT:    movd %xmm2, %eax
; X86-64-NEXT:    testl %eax, %eax
; X86-64-NEXT:    je .LBB0_2
; X86-64-NEXT:  # %bb.1:
; X86-64-NEXT:    movaps %xmm4, %xmm2
; X86-64-NEXT:  .LBB0_2:
; X86-64-NEXT:    movaps %xmm1, %xmm0
; X86-64-NEXT:    andnps %xmm4, %xmm0
; X86-64-NEXT:    movd %xmm3, %eax
; X86-64-NEXT:    testl %eax, %eax
; X86-64-NEXT:    je .LBB0_4
; X86-64-NEXT:  # %bb.3:
; X86-64-NEXT:    movaps %xmm2, %xmm3
; X86-64-NEXT:  .LBB0_4:
; X86-64-NEXT:    andps %xmm3, %xmm1
; X86-64-NEXT:    orps %xmm1, %xmm0
; X86-64-NEXT:    retq
  %z = call float @llvm.maximumnum.f32(float %x, float %y)
  ret float %z
}

define float @maximumnum_float_nsz(float %x, float %y) {
;
; X86-64-LABEL: maximumnum_float_nsz:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movaps %xmm0, %xmm2
; X86-64-NEXT:    cmpunordss %xmm0, %xmm2
; X86-64-NEXT:    movaps %xmm2, %xmm3
; X86-64-NEXT:    andps %xmm1, %xmm3
; X86-64-NEXT:    andnps %xmm0, %xmm2
; X86-64-NEXT:    orps %xmm3, %xmm2
; X86-64-NEXT:    movaps %xmm1, %xmm0
; X86-64-NEXT:    cmpunordss %xmm1, %xmm0
; X86-64-NEXT:    movaps %xmm0, %xmm3
; X86-64-NEXT:    andps %xmm2, %xmm3
; X86-64-NEXT:    andnps %xmm1, %xmm0
; X86-64-NEXT:    orps %xmm3, %xmm0
; X86-64-NEXT:    movaps %xmm0, %xmm1
; X86-64-NEXT:    cmpltss %xmm2, %xmm1
; X86-64-NEXT:    andps %xmm1, %xmm2
; X86-64-NEXT:    andnps %xmm0, %xmm1
; X86-64-NEXT:    orps %xmm2, %xmm1
; X86-64-NEXT:    movaps %xmm1, %xmm2
; X86-64-NEXT:    addss %xmm1, %xmm2
; X86-64-NEXT:    movaps %xmm1, %xmm0
; X86-64-NEXT:    cmpunordss %xmm1, %xmm0
; X86-64-NEXT:    andps %xmm0, %xmm2
; X86-64-NEXT:    andnps %xmm1, %xmm0
; X86-64-NEXT:    orps %xmm2, %xmm0
; X86-64-NEXT:    retq
  %z = call nsz float @llvm.maximumnum.f32(float %x, float %y)
  ret float %z
}

define float @maximumnum_float_nnan(float %x, float %y) {
;
; X86-64-LABEL: maximumnum_float_nnan:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movd %xmm0, %eax
; X86-64-NEXT:    testl %eax, %eax
; X86-64-NEXT:    js .LBB2_1
; X86-64-NEXT:  # %bb.2:
; X86-64-NEXT:    movdqa %xmm0, %xmm2
; X86-64-NEXT:    jmp .LBB2_3
; X86-64-NEXT:  .LBB2_1:
; X86-64-NEXT:    movdqa %xmm1, %xmm2
; X86-64-NEXT:    movdqa %xmm0, %xmm1
; X86-64-NEXT:  .LBB2_3:
; X86-64-NEXT:    maxss %xmm2, %xmm1
; X86-64-NEXT:    movaps %xmm1, %xmm0
; X86-64-NEXT:    retq
  %z = call nnan float @llvm.maximumnum.f32(float %x, float %y)
  ret float %z
}


define double @maximumnum_double(double %x, double %y) {
;
; X86-64-LABEL: maximumnum_double:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movapd %xmm0, %xmm2
; X86-64-NEXT:    cmpunordsd %xmm0, %xmm2
; X86-64-NEXT:    movapd %xmm2, %xmm3
; X86-64-NEXT:    andpd %xmm1, %xmm3
; X86-64-NEXT:    andnpd %xmm0, %xmm2
; X86-64-NEXT:    orpd %xmm3, %xmm2
; X86-64-NEXT:    movapd %xmm1, %xmm3
; X86-64-NEXT:    cmpunordsd %xmm1, %xmm3
; X86-64-NEXT:    movapd %xmm3, %xmm0
; X86-64-NEXT:    andpd %xmm2, %xmm0
; X86-64-NEXT:    andnpd %xmm1, %xmm3
; X86-64-NEXT:    orpd %xmm0, %xmm3
; X86-64-NEXT:    movapd %xmm3, %xmm0
; X86-64-NEXT:    cmpltsd %xmm2, %xmm0
; X86-64-NEXT:    movapd %xmm0, %xmm1
; X86-64-NEXT:    andpd %xmm2, %xmm1
; X86-64-NEXT:    andnpd %xmm3, %xmm0
; X86-64-NEXT:    orpd %xmm1, %xmm0
; X86-64-NEXT:    movapd %xmm0, %xmm1
; X86-64-NEXT:    addsd %xmm0, %xmm1
; X86-64-NEXT:    movapd %xmm0, %xmm4
; X86-64-NEXT:    cmpunordsd %xmm0, %xmm4
; X86-64-NEXT:    andpd %xmm4, %xmm1
; X86-64-NEXT:    andnpd %xmm0, %xmm4
; X86-64-NEXT:    orpd %xmm1, %xmm4
; X86-64-NEXT:    xorpd %xmm1, %xmm1
; X86-64-NEXT:    cmpeqsd %xmm4, %xmm1
; X86-64-NEXT:    movq %xmm2, %rax
; X86-64-NEXT:    testq %rax, %rax
; X86-64-NEXT:    je .LBB3_2
; X86-64-NEXT:  # %bb.1:
; X86-64-NEXT:    movapd %xmm4, %xmm2
; X86-64-NEXT:  .LBB3_2:
; X86-64-NEXT:    movapd %xmm1, %xmm0
; X86-64-NEXT:    andnpd %xmm4, %xmm0
; X86-64-NEXT:    movq %xmm3, %rax
; X86-64-NEXT:    testq %rax, %rax
; X86-64-NEXT:    je .LBB3_4
; X86-64-NEXT:  # %bb.3:
; X86-64-NEXT:    movapd %xmm2, %xmm3
; X86-64-NEXT:  .LBB3_4:
; X86-64-NEXT:    andpd %xmm3, %xmm1
; X86-64-NEXT:    orpd %xmm1, %xmm0
; X86-64-NEXT:    retq
  %z = call double @llvm.maximumnum.f64(double %x, double %y)
  ret double %z
}

define double @maximumnum_double_nsz(double %x, double %y) {
;
; X86-64-LABEL: maximumnum_double_nsz:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movapd %xmm0, %xmm2
; X86-64-NEXT:    cmpunordsd %xmm0, %xmm2
; X86-64-NEXT:    movapd %xmm2, %xmm3
; X86-64-NEXT:    andpd %xmm1, %xmm3
; X86-64-NEXT:    andnpd %xmm0, %xmm2
; X86-64-NEXT:    orpd %xmm3, %xmm2
; X86-64-NEXT:    movapd %xmm1, %xmm0
; X86-64-NEXT:    cmpunordsd %xmm1, %xmm0
; X86-64-NEXT:    movapd %xmm0, %xmm3
; X86-64-NEXT:    andpd %xmm2, %xmm3
; X86-64-NEXT:    andnpd %xmm1, %xmm0
; X86-64-NEXT:    orpd %xmm3, %xmm0
; X86-64-NEXT:    movapd %xmm0, %xmm1
; X86-64-NEXT:    cmpltsd %xmm2, %xmm1
; X86-64-NEXT:    andpd %xmm1, %xmm2
; X86-64-NEXT:    andnpd %xmm0, %xmm1
; X86-64-NEXT:    orpd %xmm2, %xmm1
; X86-64-NEXT:    movapd %xmm1, %xmm2
; X86-64-NEXT:    addsd %xmm1, %xmm2
; X86-64-NEXT:    movapd %xmm1, %xmm0
; X86-64-NEXT:    cmpunordsd %xmm1, %xmm0
; X86-64-NEXT:    andpd %xmm0, %xmm2
; X86-64-NEXT:    andnpd %xmm1, %xmm0
; X86-64-NEXT:    orpd %xmm2, %xmm0
; X86-64-NEXT:    retq
  %z = call nsz double @llvm.maximumnum.f64(double %x, double %y)
  ret double %z
}

define double @maximumnum_double_nnan(double %x, double %y) {
;
; X86-64-LABEL: maximumnum_double_nnan:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movq %xmm0, %rax
; X86-64-NEXT:    testq %rax, %rax
; X86-64-NEXT:    js .LBB5_1
; X86-64-NEXT:  # %bb.2:
; X86-64-NEXT:    movdqa %xmm0, %xmm2
; X86-64-NEXT:    jmp .LBB5_3
; X86-64-NEXT:  .LBB5_1:
; X86-64-NEXT:    movdqa %xmm1, %xmm2
; X86-64-NEXT:    movdqa %xmm0, %xmm1
; X86-64-NEXT:  .LBB5_3:
; X86-64-NEXT:    maxsd %xmm2, %xmm1
; X86-64-NEXT:    movapd %xmm1, %xmm0
; X86-64-NEXT:    retq
  %z = call nnan double @llvm.maximumnum.f64(double %x, double %y)
  ret double %z
}

define float @minimumnum_float(float %x, float %y) {
;
; X86-64-LABEL: minimumnum_float:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movaps %xmm0, %xmm2
; X86-64-NEXT:    cmpunordss %xmm0, %xmm2
; X86-64-NEXT:    movaps %xmm2, %xmm3
; X86-64-NEXT:    andps %xmm1, %xmm3
; X86-64-NEXT:    andnps %xmm0, %xmm2
; X86-64-NEXT:    orps %xmm3, %xmm2
; X86-64-NEXT:    movaps %xmm1, %xmm3
; X86-64-NEXT:    cmpunordss %xmm1, %xmm3
; X86-64-NEXT:    movaps %xmm3, %xmm0
; X86-64-NEXT:    andps %xmm2, %xmm0
; X86-64-NEXT:    andnps %xmm1, %xmm3
; X86-64-NEXT:    orps %xmm0, %xmm3
; X86-64-NEXT:    movaps %xmm2, %xmm0
; X86-64-NEXT:    cmpltss %xmm3, %xmm0
; X86-64-NEXT:    movaps %xmm0, %xmm1
; X86-64-NEXT:    andps %xmm2, %xmm1
; X86-64-NEXT:    andnps %xmm3, %xmm0
; X86-64-NEXT:    orps %xmm1, %xmm0
; X86-64-NEXT:    movaps %xmm0, %xmm1
; X86-64-NEXT:    addss %xmm0, %xmm1
; X86-64-NEXT:    movaps %xmm0, %xmm4
; X86-64-NEXT:    cmpunordss %xmm0, %xmm4
; X86-64-NEXT:    andps %xmm4, %xmm1
; X86-64-NEXT:    andnps %xmm0, %xmm4
; X86-64-NEXT:    orps %xmm1, %xmm4
; X86-64-NEXT:    xorps %xmm1, %xmm1
; X86-64-NEXT:    cmpeqss %xmm4, %xmm1
; X86-64-NEXT:    movd %xmm2, %eax
; X86-64-NEXT:    negl %eax
; X86-64-NEXT:    jo .LBB6_2
; X86-64-NEXT:  # %bb.1:
; X86-64-NEXT:    movaps %xmm4, %xmm2
; X86-64-NEXT:  .LBB6_2:
; X86-64-NEXT:    movaps %xmm1, %xmm0
; X86-64-NEXT:    andnps %xmm4, %xmm0
; X86-64-NEXT:    movd %xmm3, %eax
; X86-64-NEXT:    negl %eax
; X86-64-NEXT:    jo .LBB6_4
; X86-64-NEXT:  # %bb.3:
; X86-64-NEXT:    movaps %xmm2, %xmm3
; X86-64-NEXT:  .LBB6_4:
; X86-64-NEXT:    andps %xmm3, %xmm1
; X86-64-NEXT:    orps %xmm1, %xmm0
; X86-64-NEXT:    retq
  %z = call float @llvm.minimumnum.f32(float %x, float %y)
  ret float %z
}

define float @minimumnum_float_nsz(float %x, float %y) {
;
; X86-64-LABEL: minimumnum_float_nsz:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movaps %xmm0, %xmm2
; X86-64-NEXT:    cmpunordss %xmm0, %xmm2
; X86-64-NEXT:    movaps %xmm2, %xmm3
; X86-64-NEXT:    andps %xmm1, %xmm3
; X86-64-NEXT:    andnps %xmm0, %xmm2
; X86-64-NEXT:    orps %xmm3, %xmm2
; X86-64-NEXT:    movaps %xmm1, %xmm0
; X86-64-NEXT:    cmpunordss %xmm1, %xmm0
; X86-64-NEXT:    movaps %xmm0, %xmm3
; X86-64-NEXT:    andps %xmm2, %xmm3
; X86-64-NEXT:    andnps %xmm1, %xmm0
; X86-64-NEXT:    orps %xmm3, %xmm0
; X86-64-NEXT:    movaps %xmm2, %xmm1
; X86-64-NEXT:    cmpltss %xmm0, %xmm1
; X86-64-NEXT:    andps %xmm1, %xmm2
; X86-64-NEXT:    andnps %xmm0, %xmm1
; X86-64-NEXT:    orps %xmm2, %xmm1
; X86-64-NEXT:    movaps %xmm1, %xmm2
; X86-64-NEXT:    addss %xmm1, %xmm2
; X86-64-NEXT:    movaps %xmm1, %xmm0
; X86-64-NEXT:    cmpunordss %xmm1, %xmm0
; X86-64-NEXT:    andps %xmm0, %xmm2
; X86-64-NEXT:    andnps %xmm1, %xmm0
; X86-64-NEXT:    orps %xmm2, %xmm0
; X86-64-NEXT:    retq
  %z = call nsz float @llvm.minimumnum.f32(float %x, float %y)
  ret float %z
}

define float @minimumnum_float_nnan(float %x, float %y) {
;
; X86-64-LABEL: minimumnum_float_nnan:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movd %xmm0, %eax
; X86-64-NEXT:    testl %eax, %eax
; X86-64-NEXT:    js .LBB8_1
; X86-64-NEXT:  # %bb.2:
; X86-64-NEXT:    minss %xmm1, %xmm0
; X86-64-NEXT:    retq
; X86-64-NEXT:  .LBB8_1:
; X86-64-NEXT:    movdqa %xmm0, %xmm2
; X86-64-NEXT:    movaps %xmm1, %xmm0
; X86-64-NEXT:    minss %xmm2, %xmm0
; X86-64-NEXT:    retq
  %z = call nnan float @llvm.minimumnum.f32(float %x, float %y)
  ret float %z
}

define double @minimumnum_double(double %x, double %y) {
;
; X86-64-LABEL: minimumnum_double:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movapd %xmm0, %xmm2
; X86-64-NEXT:    cmpunordsd %xmm0, %xmm2
; X86-64-NEXT:    movapd %xmm2, %xmm3
; X86-64-NEXT:    andpd %xmm1, %xmm3
; X86-64-NEXT:    andnpd %xmm0, %xmm2
; X86-64-NEXT:    orpd %xmm3, %xmm2
; X86-64-NEXT:    movapd %xmm1, %xmm3
; X86-64-NEXT:    cmpunordsd %xmm1, %xmm3
; X86-64-NEXT:    movapd %xmm3, %xmm0
; X86-64-NEXT:    andpd %xmm2, %xmm0
; X86-64-NEXT:    andnpd %xmm1, %xmm3
; X86-64-NEXT:    orpd %xmm0, %xmm3
; X86-64-NEXT:    movapd %xmm2, %xmm0
; X86-64-NEXT:    cmpltsd %xmm3, %xmm0
; X86-64-NEXT:    movapd %xmm0, %xmm1
; X86-64-NEXT:    andpd %xmm2, %xmm1
; X86-64-NEXT:    andnpd %xmm3, %xmm0
; X86-64-NEXT:    orpd %xmm1, %xmm0
; X86-64-NEXT:    movapd %xmm0, %xmm1
; X86-64-NEXT:    addsd %xmm0, %xmm1
; X86-64-NEXT:    movapd %xmm0, %xmm4
; X86-64-NEXT:    cmpunordsd %xmm0, %xmm4
; X86-64-NEXT:    andpd %xmm4, %xmm1
; X86-64-NEXT:    andnpd %xmm0, %xmm4
; X86-64-NEXT:    orpd %xmm1, %xmm4
; X86-64-NEXT:    xorpd %xmm1, %xmm1
; X86-64-NEXT:    cmpeqsd %xmm4, %xmm1
; X86-64-NEXT:    movq %xmm2, %rax
; X86-64-NEXT:    negq %rax
; X86-64-NEXT:    jo .LBB9_2
; X86-64-NEXT:  # %bb.1:
; X86-64-NEXT:    movapd %xmm4, %xmm2
; X86-64-NEXT:  .LBB9_2:
; X86-64-NEXT:    movapd %xmm1, %xmm0
; X86-64-NEXT:    andnpd %xmm4, %xmm0
; X86-64-NEXT:    movq %xmm3, %rax
; X86-64-NEXT:    negq %rax
; X86-64-NEXT:    jo .LBB9_4
; X86-64-NEXT:  # %bb.3:
; X86-64-NEXT:    movapd %xmm2, %xmm3
; X86-64-NEXT:  .LBB9_4:
; X86-64-NEXT:    andpd %xmm3, %xmm1
; X86-64-NEXT:    orpd %xmm1, %xmm0
; X86-64-NEXT:    retq
  %z = call double @llvm.minimumnum.f64(double %x, double %y)
  ret double %z
}

define double @minimumnum_double_nsz(double %x, double %y) {
;
; X86-64-LABEL: minimumnum_double_nsz:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movapd %xmm0, %xmm2
; X86-64-NEXT:    cmpunordsd %xmm0, %xmm2
; X86-64-NEXT:    movapd %xmm2, %xmm3
; X86-64-NEXT:    andpd %xmm1, %xmm3
; X86-64-NEXT:    andnpd %xmm0, %xmm2
; X86-64-NEXT:    orpd %xmm3, %xmm2
; X86-64-NEXT:    movapd %xmm1, %xmm0
; X86-64-NEXT:    cmpunordsd %xmm1, %xmm0
; X86-64-NEXT:    movapd %xmm0, %xmm3
; X86-64-NEXT:    andpd %xmm2, %xmm3
; X86-64-NEXT:    andnpd %xmm1, %xmm0
; X86-64-NEXT:    orpd %xmm3, %xmm0
; X86-64-NEXT:    movapd %xmm2, %xmm1
; X86-64-NEXT:    cmpltsd %xmm0, %xmm1
; X86-64-NEXT:    andpd %xmm1, %xmm2
; X86-64-NEXT:    andnpd %xmm0, %xmm1
; X86-64-NEXT:    orpd %xmm2, %xmm1
; X86-64-NEXT:    movapd %xmm1, %xmm2
; X86-64-NEXT:    addsd %xmm1, %xmm2
; X86-64-NEXT:    movapd %xmm1, %xmm0
; X86-64-NEXT:    cmpunordsd %xmm1, %xmm0
; X86-64-NEXT:    andpd %xmm0, %xmm2
; X86-64-NEXT:    andnpd %xmm1, %xmm0
; X86-64-NEXT:    orpd %xmm2, %xmm0
; X86-64-NEXT:    retq
  %z = call nsz double @llvm.minimumnum.f64(double %x, double %y)
  ret double %z
}

define double @minimumnum_double_nnan(double %x, double %y) {
;
; X86-64-LABEL: minimumnum_double_nnan:
; X86-64:       # %bb.0:
; X86-64-NEXT:    movq %xmm0, %rax
; X86-64-NEXT:    testq %rax, %rax
; X86-64-NEXT:    js .LBB11_1
; X86-64-NEXT:  # %bb.2:
; X86-64-NEXT:    minsd %xmm1, %xmm0
; X86-64-NEXT:    retq
; X86-64-NEXT:  .LBB11_1:
; X86-64-NEXT:    movdqa %xmm0, %xmm2
; X86-64-NEXT:    movapd %xmm1, %xmm0
; X86-64-NEXT:    minsd %xmm2, %xmm0
; X86-64-NEXT:    retq
  %z = call nnan double @llvm.minimumnum.f64(double %x, double %y)
  ret double %z
}
