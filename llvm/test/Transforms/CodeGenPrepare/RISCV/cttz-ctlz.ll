; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S -passes='require<profile-summary>,function(codegenprepare)' < %s | FileCheck %s --check-prefixes=CHECK,SLOW
; RUN: opt -S -mattr=+rva22u64 -passes='require<profile-summary>,function(codegenprepare)' < %s | FileCheck %s --check-prefixes=CHECK,FAST
target triple = "riscv64-unknown-unknown"

; Check that despeculating count-zeros intrinsics doesn't crash when those
; intrinsics use scalable types.

define <vscale x 4 x i64> @cttz_nxv4i64(<vscale x 4 x i64> %x) {
; CHECK-LABEL: @cttz_nxv4i64(
; CHECK-NEXT:    [[Z:%.*]] = call <vscale x 4 x i64> @llvm.cttz.nxv4i64(<vscale x 4 x i64> [[X:%.*]], i1 false)
; CHECK-NEXT:    ret <vscale x 4 x i64> [[Z]]
;
  %z = call <vscale x 4 x i64> @llvm.cttz.nxv4i64(<vscale x 4 x i64> %x, i1 false)
  ret <vscale x 4 x i64> %z
}

define <vscale x 4 x i64> @ctlz_nxv4i64(<vscale x 4 x i64> %x) {
; CHECK-LABEL: @ctlz_nxv4i64(
; CHECK-NEXT:    [[Z:%.*]] = call <vscale x 4 x i64> @llvm.ctlz.nxv4i64(<vscale x 4 x i64> [[X:%.*]], i1 false)
; CHECK-NEXT:    ret <vscale x 4 x i64> [[Z]]
;
  %z = call <vscale x 4 x i64> @llvm.ctlz.nxv4i64(<vscale x 4 x i64> %x, i1 false)
  ret <vscale x 4 x i64> %z
}

; If the intrinsic is cheap, nothing should change.
; If the intrinsic is expensive, check if the input is zero to avoid the call.
; This is undoing speculation that may have been created by SimplifyCFG + InstCombine.

define i64 @cttz(i64 %A) {
; SLOW-LABEL: @cttz(
; SLOW-NEXT:  entry:
; SLOW-NEXT:    [[A_FR:%.*]] = freeze i64 [[A:%.*]]
; SLOW-NEXT:    [[CMPZ:%.*]] = icmp eq i64 [[A_FR]], 0
; SLOW-NEXT:    br i1 [[CMPZ]], label [[COND_END:%.*]], label [[COND_FALSE:%.*]]
; SLOW:       cond.false:
; SLOW-NEXT:    [[Z:%.*]] = call i64 @llvm.cttz.i64(i64 [[A_FR]], i1 true)
; SLOW-NEXT:    br label [[COND_END]]
; SLOW:       cond.end:
; SLOW-NEXT:    [[CTZ:%.*]] = phi i64 [ 64, [[ENTRY:%.*]] ], [ [[Z]], [[COND_FALSE]] ]
; SLOW-NEXT:    ret i64 [[CTZ]]
;
; FAST-LABEL: @cttz(
; FAST-NEXT:  entry:
; FAST-NEXT:    [[Z:%.*]] = call i64 @llvm.cttz.i64(i64 [[A:%.*]], i1 false)
; FAST-NEXT:    ret i64 [[Z]]
;
entry:
  %z = call i64 @llvm.cttz.i64(i64 %A, i1 false)
  ret i64 %z
}

define i64 @ctlz(i64 %A) {
; SLOW-LABEL: @ctlz(
; SLOW-NEXT:  entry:
; SLOW-NEXT:    [[A_FR:%.*]] = freeze i64 [[A:%.*]]
; SLOW-NEXT:    [[CMPZ:%.*]] = icmp eq i64 [[A_FR]], 0
; SLOW-NEXT:    br i1 [[CMPZ]], label [[COND_END:%.*]], label [[COND_FALSE:%.*]]
; SLOW:       cond.false:
; SLOW-NEXT:    [[Z:%.*]] = call i64 @llvm.ctlz.i64(i64 [[A_FR]], i1 true)
; SLOW-NEXT:    br label [[COND_END]]
; SLOW:       cond.end:
; SLOW-NEXT:    [[CTZ:%.*]] = phi i64 [ 64, [[ENTRY:%.*]] ], [ [[Z]], [[COND_FALSE]] ]
; SLOW-NEXT:    ret i64 [[CTZ]]
;
; FAST-LABEL: @ctlz(
; FAST-NEXT:  entry:
; FAST-NEXT:    [[Z:%.*]] = call i64 @llvm.ctlz.i64(i64 [[A:%.*]], i1 false)
; FAST-NEXT:    ret i64 [[Z]]
;
entry:
  %z = call i64 @llvm.ctlz.i64(i64 %A, i1 false)
  ret i64 %z
}

define i8 @cttz_i8(i8 %A) {
; SLOW-LABEL: @cttz_i8(
; SLOW-NEXT:  entry:
; SLOW-NEXT:    [[A_FR:%.*]] = freeze i8 [[A:%.*]]
; SLOW-NEXT:    [[CMPZ:%.*]] = icmp eq i8 [[A_FR]], 0
; SLOW-NEXT:    br i1 [[CMPZ]], label [[COND_END:%.*]], label [[COND_FALSE:%.*]]
; SLOW:       cond.false:
; SLOW-NEXT:    [[Z:%.*]] = call i8 @llvm.cttz.i8(i8 [[A_FR]], i1 true)
; SLOW-NEXT:    br label [[COND_END]]
; SLOW:       cond.end:
; SLOW-NEXT:    [[CTZ:%.*]] = phi i8 [ 8, [[ENTRY:%.*]] ], [ [[Z]], [[COND_FALSE]] ]
; SLOW-NEXT:    ret i8 [[CTZ]]
;
; FAST-LABEL: @cttz_i8(
; FAST-NEXT:  entry:
; FAST-NEXT:    [[Z:%.*]] = call i8 @llvm.cttz.i8(i8 [[A:%.*]], i1 false)
; FAST-NEXT:    ret i8 [[Z]]
;
  entry:
  %z = call i8 @llvm.cttz.i8(i8 %A, i1 false)
  ret i8 %z
}

define i8 @ctlz_i8(i8 %A) {
; SLOW-LABEL: @ctlz_i8(
; SLOW-NEXT:  entry:
; SLOW-NEXT:    [[A_FR:%.*]] = freeze i8 [[A:%.*]]
; SLOW-NEXT:    [[CMPZ:%.*]] = icmp eq i8 [[A_FR]], 0
; SLOW-NEXT:    br i1 [[CMPZ]], label [[COND_END:%.*]], label [[COND_FALSE:%.*]]
; SLOW:       cond.false:
; SLOW-NEXT:    [[Z:%.*]] = call i8 @llvm.ctlz.i8(i8 [[A_FR]], i1 true)
; SLOW-NEXT:    br label [[COND_END]]
; SLOW:       cond.end:
; SLOW-NEXT:    [[CTZ:%.*]] = phi i8 [ 8, [[ENTRY:%.*]] ], [ [[Z]], [[COND_FALSE]] ]
; SLOW-NEXT:    ret i8 [[CTZ]]
;
; FAST-LABEL: @ctlz_i8(
; FAST-NEXT:  entry:
; FAST-NEXT:    [[Z:%.*]] = call i8 @llvm.ctlz.i8(i8 [[A:%.*]], i1 false)
; FAST-NEXT:    ret i8 [[Z]]
;
  entry:
  %z = call i8 @llvm.ctlz.i8(i8 %A, i1 false)
  ret i8 %z
}

; As the operand will be promoted by the type legalizer, no despeculation when counting
; ones.

define i8 @ctto_i8_no_despeculation(i8 %A) {
; CHECK-LABEL: @ctto_i8_no_despeculation(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[A_NOT:%.*]] = xor i8 [[A:%.*]], -1
; CHECK-NEXT:    [[Z:%.*]] = call i8 @llvm.cttz.i8(i8 [[A_NOT]], i1 false)
; CHECK-NEXT:    ret i8 [[Z]]
;
  entry:
  %A.not = xor i8 %A, -1
  %z = call i8 @llvm.cttz.i8(i8 %A.not, i1 false)
  ret i8 %z
}

define i8 @ctlo_i8_no_despeculation(i8 %A) {
; CHECK-LABEL: @ctlo_i8_no_despeculation(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[A_NOT:%.*]] = xor i8 [[A:%.*]], -1
; CHECK-NEXT:    [[Z:%.*]] = call i8 @llvm.ctlz.i8(i8 [[A_NOT]], i1 false)
; CHECK-NEXT:    ret i8 [[Z]]
;
  entry:
  %A.not = xor i8 %A, -1
  %z = call i8 @llvm.ctlz.i8(i8 %A.not, i1 false)
  ret i8 %z
}

declare <vscale x 4 x i64> @llvm.cttz.nxv4i64(<vscale x 4 x i64>, i1)
declare <vscale x 4 x i64> @llvm.ctlz.nxv4i64(<vscale x 4 x i64>, i1)
declare i64 @llvm.cttz.i64(i64, i1)
declare i64 @llvm.ctlz.i64(i64, i1)
declare i8 @llvm.cttz.i8(i8, i1)
declare i8 @llvm.ctlz.i8(i8, i1)
